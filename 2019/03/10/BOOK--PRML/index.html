<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="default">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.3" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.3">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.3">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.3" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta name="description" content="Machine Learning Course in Spring 2019
Text Book: Pattern Recognition and Machine Learning, Bishop
Here are my learning notes, to be continued..ğŸ˜
IntroductionSupervised Learning
regression: y is cont">
<meta property="og:type" content="article">
<meta property="og:title" content="BOOK--PRML">
<meta property="og:url" content="http://yoursite.com/2019/03/10/BOOK--PRML/index.html">
<meta property="og:site_name" content="Ace">
<meta property="og:description" content="Machine Learning Course in Spring 2019
Text Book: Pattern Recognition and Machine Learning, Bishop
Here are my learning notes, to be continued..ğŸ˜
IntroductionSupervised Learning
regression: y is cont">
<meta property="og:updated_time" content="2019-04-03T09:05:40.096Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="BOOK--PRML">
<meta name="twitter:description" content="Machine Learning Course in Spring 2019
Text Book: Pattern Recognition and Machine Learning, Bishop
Here are my learning notes, to be continued..ğŸ˜
IntroductionSupervised Learning
regression: y is cont">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.3',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2019/03/10/BOOK--PRML/"/>





  <title>BOOK--PRML | Ace</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ace</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Ace.github.io</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-categories"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/10/BOOK--PRML/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ace_ZAJ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/me.JPG">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ace">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">BOOK--PRML</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-03-10T20:25:21+08:00">
                2019-03-10
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Machine Learning Course in Spring 2019</p>
<p>Text Book: Pattern Recognition and Machine Learning, Bishop</p>
<p>Here are my learning notes, to be continued..ğŸ˜</p>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><h4 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h4><ul>
<li>regression: y is continuous</li>
<li>classification: y is discrete</li>
</ul>
<p>supervised+X learning</p>
<h4 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h4><ul>
<li>Cluster: well-seperated</li>
<li>Dimensionality reduction</li>
</ul>
<h4 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h4><a id="more"></a>
<h2 id="Basic-steps"><a href="#Basic-steps" class="headerlink" title="Basic steps"></a>Basic steps</h2><h4 id="generalization-error"><a href="#generalization-error" class="headerlink" title="generalization error"></a>generalization error</h4><p>Training error &amp; True(<strong>generalization error</strong>) â€“ over the whole population</p>
<p>generalization error is the true error of the population of examples, but it cannot be computed exactly, sample mean <strong>only approximates</strong> the true mean</p>
<p>Optimize (mean) training error can lead to the <strong>overfit</strong></p>
<p>2 ways to assess the generalization error is:</p>
<ul>
<li>Theoretical: Law of Large numbers</li>
<li>Practical: Use a separate data set with m data samples to test the model</li>
</ul>
<h4 id="Test-sets"><a href="#Test-sets" class="headerlink" title="Test sets"></a>Test sets</h4><p>How can we get an unbiased estimate of the accuracy of a learned model?</p>
<p>When learning a model, should pretend that you donâ€™t have the test data yet</p>
<p><strong>The empirical loss</strong></p>
<h4 id="Overfitting"><a href="#Overfitting" class="headerlink" title="Overfitting"></a>Overfitting</h4><p>when the training error is low and the generalization error is high</p>
<p>Causes of phenomenon:</p>
<ul>
<li>model with a large number of parameters (degrees of freedom)</li>
<li>small data size</li>
</ul>
<h4 id="Feature-selection"><a href="#Feature-selection" class="headerlink" title="Feature selection"></a>Feature selection</h4><p>score each feature and select a subset</p>
<h4 id="Model-selection"><a href="#Model-selection" class="headerlink" title="Model selection"></a>Model selection</h4><p>solution for overfitting:</p>
<ul>
<li>assure sufficient number of samples in the training set</li>
<li>hold some data out of the training set = validation set</li>
<li>regularization</li>
</ul>
<p>Validation set, Hold-out method &amp; its drawbacks</p>
<p>Cross validation:</p>
<ul>
<li>K-fold cross validation</li>
<li>Leave-out-out (LOO) cross validation, validate on only one sample per run for n runs</li>
<li>Random subsampling: randomly subsample a fixed fraction an (0&lt;a&lt;1) of the dataset for validation</li>
</ul>
<h4 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h4><p>penalized loss function</p>
<p>regularization parameter</p>
<h2 id="1-Polynomial-Curve-Regression-â€“-Bishop-page10"><a href="#1-Polynomial-Curve-Regression-â€“-Bishop-page10" class="headerlink" title="1. Polynomial Curve Regression â€“ Bishop page10"></a>1. Polynomial Curve Regression â€“ Bishop page10</h2><p>$$<br>y(x,w)=w_0+w_1x+w_2x^2+â€¦+w_mx^M=\sum_{j=0}^Mw_jx^j<br>$$</p>
<p>y(x,w) is a nonlinear function of xï¼Œit is a <strong>linear function of the coefficients w</strong></p>
<p>Error function E(<strong>w</strong>)ï¼Œminimization of the error function has a unique solutionï¼Œdenoted by w<em><br>$$<br>E(w) = \frac{1}{2}\sum_{n=1}^N{y(x_n,w)-t_n}^2<br>$$<br>Dependence of the generalization performance on M, for each choice of M, itâ€™s sometimes more convenient to use the root-mean-square(RMS) error, N - data size<br>$$<br>E_{RMS} = \sqrt{2E(w^</em>)/N}<br>$$<br>For a given model complexity, the <strong>over-fitting problem</strong> become less severe as the <strong>size of the data set increases</strong></p>
<p>The <strong>least squares approach</strong> to finding the model parameters represents a <strong>specific case of maximum likelihood</strong>. The <strong>overfitting problem</strong> can be understood as a general property of maximum likelihood. By adopting a Bayesian approach, the overfitting problem can be avoided</p>
<h3 id="Regularization-1"><a href="#Regularization-1" class="headerlink" title="Regularization"></a>Regularization</h3><p>$$<br>E(w) = \frac{1}{2}\sum_{n=1}^N{y(x_n,w)-t_n}^2+\frac{\lambda}{2}||w||^2<br>$$</p>
<p>$$<br>||w||^2=w_0^2+w_1^2+w_2^2+â€¦+w_M^2<br>$$</p>
<p>lambda governs the relative importance of the regularization term compared with the sum-of-squares error term. Note that often the w0 is  omitted from the regularizer</p>
<h2 id="2-Probability"><a href="#2-Probability" class="headerlink" title="2. Probability"></a>2. Probability</h2><p>sum rule:<br>$$<br>p(X)=\sum_Yp(X,Y)<br>$$<br>product rule:<br>$$<br>p(X,Y)=p(Y|X)P(X)<br>$$<br>Bayes theorem:<br>$$<br>p(Y|X)=\frac{P(X|Y)P(Y)}{p(X)}<br>$$</p>
<h3 id="Probability-densities"><a href="#Probability-densities" class="headerlink" title="Probability densities"></a>Probability densities</h3><p>$$<br>p(x)=\int p(x,y){\rm d}y<br>$$</p>
<h3 id="Expectation"><a href="#Expectation" class="headerlink" title="Expectation"></a>Expectation</h3><p>For a discrete distribution,<br>$$<br>E[f]=\sum_xp(x)f(x)<br>$$<br>For a continuous distribution,<br>$$<br>E[f]=\int p(x)f(x){\rm d}x<br>$$</p>
<p>$$<br>E[f]\approx\frac{1}{N}\sum_{n=1}^{N}f(x_n)<br>$$</p>
<p>For a conditional expectation,<br>$$<br>E_x{f|y}=\sum_xp(x|y)f(x)<br>$$</p>
<h3 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h3><p>For f(x),<br>$$<br>var[f]=E[(f(x)-E[f(x)])^2]<br>$$</p>
<p>$$<br>var[f]=E[(f(x)^2]-E[f(x)]^2<br>$$</p>
<p>covariance is,<br>$$<br>\begin{align}<br>cov[x,y]<br>&amp;= E_{x,y}[(x-E[x])(y-E[y])]\\<br>&amp;= E_{x,y}[xy]-E[x]E[y]<br>\end{align}<br>$$</p>
<h2 id="3-Information-Theory"><a href="#3-Information-Theory" class="headerlink" title="3. Information Theory"></a>3. Information Theory</h2><p>The amount of information can be viewed as the â€˜<strong>degree of surprise</strong>â€˜ on learning the value of x</p>
<p>If we are told that a highly improbable event that has just occurred, we will have received more information than if we were told that some very likely event that has just occurred<br>$$<br>h(x)=-log_2p(x)<br>$$<br>the negative sign ensures that information is positive or zero. <strong>Low probability events x correspond to high information content</strong></p>
<p>The average amount of information that they transmit in the process is obtained by taking the expectation, the entropy of the random variable x<br>$$<br>H[x]=-\sum p(x)log_2p(x)<br>$$<br>This relation between entropy and shortest coding length is a general one. The noiseless coding theorem states that the entropy is a lower bound on the number of bits needed to transmit the state of a random variable</p>
<h2 id="4-Likelihood-Function"><a href="#4-Likelihood-Function" class="headerlink" title="4.Likelihood Function"></a>4.Likelihood Function</h2><p>åœ¨ç¡®å®šçš„ç»“æœä¸‹å»æ¨æµ‹äº§ç”Ÿè¿™ä¸ªç»“æœçš„å¯èƒ½å‚æ•°ï¼ˆç¯å¢ƒï¼‰ï¼Œç»“æœå’Œå‚æ•°ç›¸äº’å¯¹åº”çš„æ—¶å€™ï¼Œä¼¼ç„¶å’Œæ¦‚ç‡åœ¨æ•°å€¼ä¸Šæ˜¯ç›¸ç­‰çš„<br>$$<br>\theta \text{â€“parameter}\\<br>x\text{â€“event}<br>$$<br>Probability: p(x|theta)</p>
<p>Likelihood: L(theta|x)</p>
<blockquote>
<p>Let X be a discrete random variable with probability mass function p depending on a parameter theta, Then the function </p>
</blockquote>
<p>$$<br>L(\theta|x)=p_\theta(x)=P_\theta(X=x)=P_\theta(X=x|\theta)=P_\theta(X=x;\theta)<br>$$</p>
<blockquote>
<p>Let X be a random variable following an absolutely continuous probability distribution with density function f depending on a parameter theta, Then the function </p>
</blockquote>
<p>$$<br>L(\theta|x)=f_\theta(x)<br>$$</p>
<blockquote>
<p>posterior æ­£æ¯”äº likelihood * prior</p>
</blockquote>
<p>$$<br>p(X|D) \propto p(\mu|D)*p(X)<br>$$</p>
<h2 id="5-Linear-Basic-Function-Models"><a href="#5-Linear-Basic-Function-Models" class="headerlink" title="5. Linear Basic Function Models"></a>5. Linear Basic Function Models</h2><p>Extend the class of models by considering linear combinations of fixed nonlinear functions of the input variables, of the form<br>$$<br>y(x,w)=w_0+\sum_{j=1}^{M-1}w_j\phi_j(x)\\<br>\text{when }\phi_0(x)=1, y(x,w)=w^T\phi(x)<br>$$<br>\phi(x) are known as <strong>basis functions</strong></p>
<p>By using <strong>nonlinear basis functions</strong>, we allow the function y(x, w) to be <strong>a nonlinear function of the input vector x</strong>. Functions of the form are called <strong>linear models</strong>, however, because this <strong>function is linear in w</strong>.</p>
<p><strong>Maximization of the likelihood function</strong> under a <strong>conditional Gaussian noise distribution</strong> for a linear model is equivalent to <strong>minimizing a sum-of-squares error function</strong> given by E_D(w)</p>
<h3 id="Regularized-least-squares"><a href="#Regularized-least-squares" class="headerlink" title="Regularized least squares"></a>Regularized least squares</h3><p>$$<br>E_D(w)+\lambda E_w(w)\\<br>E_w(w)=\frac{1}{2}w^Tw\\<br>\text{The total error function becomes: }\frac{1}{2}\sum_{n=1}^N{t_n-w^t\phi(x_n)}^2+\frac{\lambda}{2}w^Tw<br>$$</p>
<p>This particular choice of regularizer if known in the machine learning literature as <strong>weight decay</strong>, because in sequential learning algorithms, it encourages weight values to decay towards zero, unless supported by the data. It has the advantage that the error function remains <strong>a quadratic function of w</strong>, and so its exact minimizer can be found in <strong>closed form</strong></p>
<p>A more general regularizer is sometimes used,<br>$$<br>\frac{1}{2}\sum_{n=1}^N{t_n-w^t\phi(x_n)}^2+\frac{\lambda}{2}\sum_{j=1}^M|w_j|^q<br>$$<br>where q = 2 corresponds to the quadratic regularizer. The case of q = 1 is know as the <strong>lasso</strong> in the statistics literature</p>
<h3 id="The-Bias-Variance-Decomposition"><a href="#The-Bias-Variance-Decomposition" class="headerlink" title="The Bias-Variance Decomposition"></a>The Bias-Variance Decomposition</h3><p>expected loss = (bias)^2 + variance + noise</p>
<p>There is a trade-off between bias and variance, with very flexible models having low bias and high variance, and relatively rigid models having high bias and low variance. The model with the optimal predictive capability is the one that leads to the best balance between bias and variance.</p>
<p>We see that <strong>small values of Î»</strong> allow the model to become <strong>finely tuned to the noise</strong> on each individual data set leading to <strong>large variance</strong>. Conversely, a <strong>large value of Î» pulls the weight parameters towards zero</strong> leading to <strong>large bias</strong>.</p>
<h3 id="Bayesian-Linear-Regression"><a href="#Bayesian-Linear-Regression" class="headerlink" title="Bayesian Linear Regression"></a>Bayesian Linear Regression</h3><p>Bayesian treatment of linear regression, which will <strong>avoid the over-fitting problem of maximum likelihood</strong>, and which will also lead to <strong>automatic methods of determining model complexity</strong> using the training data alone.</p>
<h2 id="6-SVM-â€“-Support-Vector-Machine"><a href="#6-SVM-â€“-Support-Vector-Machine" class="headerlink" title="6. SVM â€“ Support Vector Machine"></a>6. SVM â€“ Support Vector Machine</h2><p>[From Lihang ç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼Œå‘¨å¿—åè¥¿ç“œä¹¦(è¿™éƒ¨åˆ†å¾ˆä¸é”™å“Ÿ)ï¼Œso ChineseğŸ˜]</p>
<p>äºŒåˆ†ç±»æ¨¡å‹ï¼ŒåŸºæœ¬æ¨¡å‹æ˜¯å®šä¹‰åœ¨ç‰¹å¾ç©ºé—´ä¸Šçš„é—´éš”æœ€å¤§çš„çº¿æ€§åˆ†ç±»å™¨ï¼Œé—´éš”æœ€å¤§ä½¿å®ƒæœ‰åˆ«äºæ„ŸçŸ¥æœº</p>
<p>æ”¯æŒå‘é‡è¿˜åŒ…æ‹¬<strong>æ ¸æŠ€å·§</strong>ï¼Œä½¿ä»–æˆä¸ºå®è´¨ä¸Šçš„<strong>éçº¿æ€§åˆ†ç±»å™¨</strong>ï¼Œæ”¯æŒå‘é‡æœºçš„å­¦ä¹ ç­–ç•¥å°±æ˜¯é—´éš”æœ€å¤§åŒ–ï¼Œå½¢å¼åŒ–ä¸ºä¸€ä¸ªæ±‚è§£å‡¸äºŒæ¬¡è§„åˆ’é—®é¢˜ï¼ˆconvex quadratic programming)</p>
<p>åˆ†ç±»ï¼š</p>
<ul>
<li>çº¿æ€§å¯åˆ†æ”¯æŒå‘é‡æœºï¼ˆlinear support vector machine in linearly separable caseï¼‰</li>
<li>çº¿æ€§æ”¯æŒå‘é‡æœºï¼ˆlinear support vector machineï¼‰</li>
<li>éçº¿æ€§æ”¯æŒå‘é‡æœºï¼ˆnon-linear support vector machine)</li>
</ul>
<p>Good explanation: <a href="https://zhuanlan.zhihu.com/p/49331510" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/49331510</a></p>
<h3 id="æ‹‰æ ¼æœ—æ—¥ä¹˜æ³•å’ŒKKTæ¡ä»¶"><a href="#æ‹‰æ ¼æœ—æ—¥ä¹˜æ³•å’ŒKKTæ¡ä»¶" class="headerlink" title="æ‹‰æ ¼æœ—æ—¥ä¹˜æ³•å’ŒKKTæ¡ä»¶"></a>æ‹‰æ ¼æœ—æ—¥ä¹˜æ³•å’ŒKKTæ¡ä»¶</h3><p>æ‹‰æ ¼æœ—æ—¥æ¯”è¾ƒç†Ÿæ‚‰ï¼Œso skip</p>
<p>read more: <a href="https://charlesliuyx.github.io/2017/09/20/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%B3%95%E5%92%8CKKT%E6%9D%A1%E4%BB%B6/" target="_blank" rel="external">https://charlesliuyx.github.io/2017/09/20/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%B3%95%E5%92%8CKKT%E6%9D%A1%E4%BB%B6/</a></p>
<p>KKT conditionï¼ŒKarush-Kuhn-Tucker Conditionsï¼Œç›¸æ¯”è¾ƒäºæ‹‰æ ¼æœ—æ—¥â€“ç­‰å¼çº¦æŸæ¡ä»¶ä¸‹ï¼ŒKKTâ€“ä¸ç­‰å¼çº¦æŸæ¡ä»¶</p>
<p>åœ¨æ»¡è¶³ä¸€äº›æœ‰è§„åˆ™çš„æ¡ä»¶ä¸‹ï¼Œä¸€ä¸ªéçº¿æ€§è§„åˆ’é—®é¢˜èƒ½æœ‰æœ€ä¼˜åŒ–è§£æ³•çš„ä¸€ä¸ªå¿…è¦å……åˆ†æ¡ä»¶<br>$$<br>minf(x),\text{ }s.t.g_i(x)\leq0<br>$$<br>å®šä¹‰æ‹‰æ ¼æœ—æ—¥ï¼š<br>$$<br>L(x,\lambda)=f(x)+\lambda g(x)<br>$$</p>
<p>$$<br>x^<em> æ˜¯å±€éƒ¨æå€¼ï¼Œå­˜åœ¨å”¯ä¸€çš„\lambda^</em> s.t.\\<br>1.\nabla_xL(x^<em>,\lambda^</em>)=0\\<br>2.\lambda^<em>\geq0\\<br>3.\lambda^</em>g(x^<em>)=0\\<br>4.g(x^</em>)\leq0\\<br>5.\text{Plus positive definite constraints on }\nabla_{xx}L(x^<em>,\lambda^</em>)<br>$$</p>
<p>read more:</p>
<p><a href="https://www.cnblogs.com/bigmonkey/p/9542545.html" target="_blank" rel="external">https://www.cnblogs.com/bigmonkey/p/9542545.html</a></p>
<p><a href="https://www.cnblogs.com/xinchen1111/p/8804858.html" target="_blank" rel="external">https://www.cnblogs.com/xinchen1111/p/8804858.html</a></p>
<h2 id="7-Graphical-Models"><a href="#7-Graphical-Models" class="headerlink" title="7. Graphical Models"></a>7. Graphical Models</h2><p>[From å‘¨å¿—åæœºå™¨å­¦ä¹ ï¼Œso summary in ChineseğŸ˜]</p>
<p><strong>Probabilistic Model</strong>ï¼šæ ¹æ®ä¸€äº›å·²è§‚å¯Ÿåˆ°çš„æ•°æ®ï¼ˆä¾‹å¦‚è®­ç»ƒæ ·æœ¬ï¼‰æ¥å¯¹æ„Ÿå…´è¶£çš„æœªçŸ¥å˜é‡è¿›è¡Œä¼°è®¡å’Œæ¨æµ‹ï¼Œå…¶æ ¸å¿ƒæ˜¯å¦‚ä½•åŸºäºå¯è§‚æµ‹å˜é‡æ¨æµ‹å‡ºæœªçŸ¥å˜é‡çš„æ¡ä»¶åˆ†å¸ƒ</p>
<p><strong>Probabilistic Graphical Model</strong>ï¼šç”¨å›¾æ¥è¡¨è¾¾å˜é‡ç›¸å…³å…³ç³»çš„æ¦‚ç‡æ¨¡å‹</p>
<ul>
<li><p><strong>æœ‰å‘</strong>æ— ç¯å›¾è¡¨ç¤ºå˜é‡ä¹‹é—´çš„ä¾èµ–å…³ç³»â€“æœ‰å‘å›¾æ¨¡å‹æˆ–<strong>è´å¶æ–¯ç½‘</strong>ï¼ˆBayesian Networkï¼‰</p>
<p><strong>éšé©¬å°”ç§‘å¤«æ¨¡å‹</strong>ï¼ˆHidden Markov Model-HMMï¼‰æ˜¯ç»“æ„æœ€ç®€å•çš„åŠ¨æ€è´å¶æ–¯ç½‘ï¼ˆdynamic Bayesian networkï¼‰ï¼Œä¸»è¦ç”¨äºæ—¶åºæ•°æ®å»ºæ¨¡ï¼Œåœ¨è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸæœ‰å¹¿æ³›åº”ç”¨</p>
</li>
<li><p><strong>æ— å‘</strong>å›¾â€“æ— å‘å›¾æ¨¡å‹æˆ–<strong>é©¬å°”å¯å¤«ç½‘</strong>ï¼ˆMarkov Networkï¼‰</p>
</li>
</ul>
<h3 id="é©¬å°”å¯å¤«é“¾ï¼ˆMarkov-Chainï¼‰"><a href="#é©¬å°”å¯å¤«é“¾ï¼ˆMarkov-Chainï¼‰" class="headerlink" title="é©¬å°”å¯å¤«é“¾ï¼ˆMarkov Chainï¼‰"></a>é©¬å°”å¯å¤«é“¾ï¼ˆMarkov Chainï¼‰</h3><p>ç³»ç»Ÿä¸‹ä¸€æ—¶åˆ»çš„çŠ¶æ€ä»…ç”±å½“å‰çŠ¶æ€å†³å®šï¼Œä¸ä¾èµ–äºä»¥å¾€çš„ä»»ä½•çŠ¶æ€<br>$$<br>P(x_1,y_1,..,x_n,y_n)=P(y_1)P(x_1|y_1)\prod_{i=2}^nP(y_i|y_{i-1})P(x_i|y_i)<br>$$</p>
<h3 id="é©¬å°”å¯å¤«éšæœºåœºï¼ˆMarkov-Random-Fieldï¼‰"><a href="#é©¬å°”å¯å¤«éšæœºåœºï¼ˆMarkov-Random-Fieldï¼‰" class="headerlink" title="é©¬å°”å¯å¤«éšæœºåœºï¼ˆMarkov Random Fieldï¼‰"></a>é©¬å°”å¯å¤«éšæœºåœºï¼ˆMarkov Random Fieldï¼‰</h3><p><strong>å…¸å‹çš„é©¬å°”å¯å¤«ç½‘</strong>ï¼Œè‘—åçš„<strong>æ— å‘å›¾æ¨¡å‹</strong></p>
<p>æœ‰ä¸€ç»„åŠ¿å‡½æ•°ï¼ˆ<strong>potential functions</strong>ï¼‰ï¼Œä¹Ÿç§°â€œå› å­â€ï¼ˆfactorï¼‰ï¼Œå®šä¹‰åœ¨å˜é‡å­é›†ä¸Šçš„éè´Ÿå®å‡½æ•°ï¼Œä¸»è¦ç”¨äº<strong>å®šä¹‰æ¦‚ç‡åˆ†å¸ƒå‡½æ•°</strong></p>
<p>â€œå›¢â€ï¼ˆCliqueï¼‰ï¼šå…¶ä¸­ä»»æ„ä¸¤ç»“ç‚¹é—´éƒ½æœ‰è¾¹è¿æ¥ï¼Œåˆ™è¯¥ç»“ç‚¹å­é›†ä¸ºä¸€ä¸ªâ€œå›¢â€ï¼›è‹¥åœ¨ä¸€ä¸ªå›¢ä¸­åŠ å…¥å¦å¤–ä»»ä½•ä¸€ä¸ªç»“ç‚¹éƒ½ä¸åœ¨å½¢æˆå›¢ï¼Œåˆ™ç§°è¯¥å›¢ä¸ºâ€œ<strong>æå¤§å›¢</strong>â€ï¼ˆmaximal cliqueï¼‰ï¼Œæå¤§å›¢æ˜¯ä¸èƒ½è¢«å…¶ä»–å›¢æ‰€åŒ…å«çš„å›¢</p>
<p>å¤šä¸ªå˜é‡ä¹‹é—´çš„è”åˆæ¦‚ç‡åˆ†å¸ƒä¹‹æ¶èƒ½åŸºäºå›¢åˆ†è§£ä¸ºå¤šä¸ªé“¶å­çš„ä¹˜ç§¯ï¼Œæ¯ä¸ªå› å­ä»…ä¸ä¸€ä¸ªå›¢ç›¸å…³<br>$$<br>P(x)=\frac{1}{Z}\prod_{Q\in C}\psi_Q(x_Q), \psi_Q \text{ä¸ºå›¢Qå¯¹åº”çš„åŠ¿å‡½æ•°}<br>$$<br>å¯åŸºäºæå¤§å›¢æ¥å®šä¹‰ï¼š<br>$$<br>P(x)=\frac{1}{Z}\prod_{Q\in C^<em>}\psi_Q(x_Q), \psi_Q \text{ä¸ºå›¢Qå¯¹åº”çš„åŠ¿å‡½æ•°},C^</em>\text{ä¸ºæ‰€æœ‰æå¤§å›¢æ„æˆçš„é›†åˆ}<br>$$<br>å€ŸåŠ©â€œåˆ†ç¦»â€çš„æ¦‚å¿µå¾—åˆ°â€œæ¡ä»¶ç‹¬ç«‹æ€§â€ï¼Œè‹¥ä»ç»“ç‚¹é›†Aä¸­çš„ç»“ç‚¹åˆ°Bä¸­çš„ç»“ç‚¹éƒ½å¿…é¡»ç»è¿‡ç»“ç‚¹Cä¸­çš„ç»“ç‚¹ï¼Œï¼Œåˆ™ç»“ç‚¹é›†Aå’ŒBéƒ½è¢«ç»“ç‚¹é›†Cåˆ†ç¦»ï¼ŒCç§°ä¸ºâ€œ<strong>åˆ†ç¦»é›†</strong>â€ï¼ˆseparating setï¼‰</p>
<p>å¯¹äºé©¬å°”å¯å¤«éšæœºåœºï¼Œæœ‰â€œ<strong>å…¨å±€é©¬å°”å¯å¤«æ€§</strong>â€ï¼šç»™å®šä¸¤ä¸ªå˜é‡å­é›†çš„åˆ†ç¦»é›†ï¼Œåˆ™è¿™ä¸¤ä¸ªå˜é‡å­é›†æ¡ä»¶ç‹¬ç«‹<br>$$<br>x_A\bot x_B|x_C<br>$$<br>åŠ¿å‡½æ•°çš„ä½œç”¨æ˜¯å®šé‡åˆ»ç”»å˜é‡é›†x_Qä¸­å˜é‡ä¹‹é—´çš„ç›¸å…³å…³ç³»ï¼Œåº”è¯¥æ˜¯<strong>éè´Ÿå‡½æ•°</strong>ï¼Œä¸”åœ¨æ‰€åå¥½çš„å˜é‡å–å€¼ä¸Šæœ‰è¾ƒå¤§å‡½æ•°å€¼ï¼Œå¤§äº1-&gt;åå¥½å˜é‡æ‹¥æœ‰ç›¸åŒçš„å–å€¼ï¼Œæ­£ç›¸å…³ï¼›å°äº1-&gt;åå¥½å˜é‡æ‹¥æœ‰ä¸åŒçš„å–å€¼ï¼Œè´Ÿç›¸å…³</p>
<h3 id="æ¡ä»¶éšæœºåœºï¼ˆConditional-Random-Field-CRFï¼‰"><a href="#æ¡ä»¶éšæœºåœºï¼ˆConditional-Random-Field-CRFï¼‰" class="headerlink" title="æ¡ä»¶éšæœºåœºï¼ˆConditional Random Field CRFï¼‰"></a>æ¡ä»¶éšæœºåœºï¼ˆConditional Random Field CRFï¼‰</h3><p>åˆ¤åˆ«å¼æ— å‘å›¾æ¨¡å‹</p>
<p><strong>ç”Ÿæˆå¼æ¨¡å‹</strong>æ—¶ç›´æ¥å¯¹è”åˆåˆ†å¸ƒè¿›è¡Œå»ºæ¨¡ï¼Œè€Œ<strong>åˆ¤åˆ«å¼æ¨¡å‹</strong>åˆ™æ˜¯å¯¹æ¡ä»¶åˆ†å¸ƒè¿›è¡Œå»ºæ¨¡</p>
<p>éšé©¬å°”ç§‘å¤«æ¨¡å‹å’Œé©¬å°”ç§‘å¤«éšæœºåœºéƒ½æ˜¯ç”Ÿæˆæ—¶æ¨¡å‹ï¼Œè€Œæ¡ä»¶éšæœºåœºåˆ™æ˜¯åˆ¤åˆ«å¼æ¨¡å‹</p>
<h2 id="8-EMç®—æ³•"><a href="#8-EMç®—æ³•" class="headerlink" title="8. EMç®—æ³•"></a>8. EMç®—æ³•</h2><p>ä¹‹å‰æ¦‚ç‡å›¾æ¨¡å‹ä¸­ï¼Œä¸€ç›´å‡è®¾è®­ç»ƒæ ·æœ¬æ‰€æœ‰å±æ€§å˜é‡çš„å€¼éƒ½å·²è¢«è§‚æµ‹åˆ°ï¼Œå³è®­ç»ƒæ ·æœ¬æ˜¯å®Œæ•´çš„ï¼Œä½†ä¼šæœ‰å­˜åœ¨â€œæœªè§‚æµ‹â€å˜é‡çš„æƒ…å†µ</p>
<p>æœªè§‚æµ‹è§‚æµ‹å˜é‡çš„å­¦åæ˜¯â€œéšå˜é‡â€ï¼ˆlatent variableï¼‰ã€‚ä»¤Xè¡¨ç¤ºå·²è§‚æµ‹å˜é‡é›†ï¼ŒZè¡¨ç¤ºå› å˜é‡é›†ï¼Œ\thetaè¡¨ç¤ºæ¨¡å‹å‚æ•°ï¼Œå¯¹\thetaè¿›è¡Œæå¤§ä¼¼ç„¶ä¼°è®¡<br>$$<br>LL(\theta|X,Z)=lnP(X,Z|\theta)<br>$$<br>æœ€å¤§åŒ–å·²è§‚æµ‹æ•°æ®çš„å¯¹æ•°â€œè¾¹é™…ä¼¼ç„¶â€ï¼ˆmarginal likelihoodï¼‰<br>$$<br>LL(\theta|X)=lnP(X|\theta)=ln\sum_ZP(X,Z|\theta)<br>$$<br>è¿­ä»£å¼æ–¹æ³•ï¼Œ<strong>åŸºæœ¬æ€æƒ³</strong>ï¼šè‹¥å‚æ•°\thetaå·²çŸ¥ï¼Œåˆ™å¯æ ¹æ®è®­ç»ƒæ•°æ®æ¨æ–­å‡ºæœ€ä¼˜éšå˜é‡Zçš„å€¼ï¼ˆEæ­¥ï¼‰ï¼›åä¹‹ï¼Œè‹¥Zçš„å€¼å·²çŸ¥ï¼Œåˆ™å¯æ–¹ä¾¿åœ°å¯¹å‚æ•°\thetaåšæå¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMæ­¥ï¼‰</p>
<p>Eæ­¥ï¼ˆExpectationï¼‰ï¼š<br>$$<br>\text{ä»¥å½“å‰å‚æ•° }\theta^tæ¨æ–­éšå˜é‡åˆ†å¸ƒP(Z|X,\theta^t),\\å¹¶ä¼°è®¡å¯¹æ•°ä¼¼ç„¶LL(\theta|X,Z)å…³äºZçš„æœŸæœ›\\<br>Q(\theta|\theta^t) =E_{Z|X,\theta^t}LL(\theta|X,Z)<br>$$<br> Mæ­¥ï¼ˆMaximizationï¼‰ï¼š<br>$$<br>å¯»æ‰¾å‚æ•°æœ€å¤§åŒ–æœŸæœ›ä¼¼ç„¶ï¼Œ\\<br>\theta^{t+1}=argmax_\theta Q(\theta|\theta^t)<br>$$<br>ä½¿ç”¨ä¸¤ä¸ªæ­¥éª¤è®¡ç®—ï¼Œç¬¬ä¸€æ­¥æ˜¯æœŸæœ›ï¼ˆEæ­¥ï¼‰ï¼Œåˆ©ç”¨å½“å‰ä¼°è®¡çš„å‚æ•°å€¼æ¥è®¡ç®—å¯¹æ•°ä¼¼ç„¶çš„æœŸæœ›å€¼ï¼›ç¬¬äºŒæ­¥æ˜¯æœ€å¤§åŒ–Mæ­¥ï¼Œå¯»æ‰¾èƒ½ä½¿Eæ­¥äº§ç”Ÿçš„ä¼¼ç„¶æœŸæœ›æœ€å¤§åŒ–çš„å‚æ•°å€¼ï¼›ç„¶åï¼Œæ–°çš„åˆ°çš„å‚æ•°å€¼é‡æ–°è¢«ç”¨äºEæ­¥ï¼Œç›´è‡³æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜è§£</p>
<p>see in: <a href="https://zhuanlan.zhihu.com/p/36331115" target="_blank" rel="external">https://zhuanlan.zhihu.com/p/36331115</a></p>
<h2 id="9-é›†æˆå­¦ä¹ "><a href="#9-é›†æˆå­¦ä¹ " class="headerlink" title="9. é›†æˆå­¦ä¹ "></a>9. é›†æˆå­¦ä¹ </h2><p>[From å‘¨å¿—åæœºå™¨å­¦ä¹ Chapter 8]</p>
<p>é›†æˆå­¦ä¹ é€šè¿‡æ„å»ºå¹¶ç»“åˆå¤šä¸ªå­¦ä¹ å™¨æ¥å®Œæˆå­¦ä¹ ä»»åŠ¡ï¼Œæœ‰æ—¶ä¹Ÿè¢«ç§°ä¸ºå¤šåˆ†ç±»å™¨ç³»ç»Ÿï¼ˆmulti-classifier systemï¼‰ã€åŸºäºå§”å‘˜ä¼šçš„å­¦ä¹ ï¼ˆcommittee-based learningï¼‰</p>
<p>é›†åˆå­¦ä¹ é€šè¿‡å°†å¤šä¸ªå­¦ä¹ å™¨ç»“åˆï¼Œå¸¸å¯è·å¾—æ¯”å•ä¸€å­¦ä¹ å™¨æ˜¾è‘—ä¼˜è¶Šçš„æ³›åŒ–æ€§èƒ½ï¼Œå¯¹â€œå¼±å­¦ä¹ å™¨â€“ç•¥ä¼˜äºéšæœºç­–ç•¥â€œå°¤ä¸ºæ˜æ˜¾</p>
<p>åˆ†ç±»ï¼š</p>
<ul>
<li>ä¸ªä½“å­¦ä¹ å™¨å­˜åœ¨å¼ºä¾èµ–å…³ç³»ã€å¿…é¡»ä¸²è¡Œç”Ÿæˆçš„åºåˆ—åŒ–æ–¹æ³•ï¼ŒBoosting</li>
<li>ä¸ªä½“å­¦ä¹ å™¨é—´ä¸å­˜åœ¨å¼ºä¾èµ–å…³ç³»ã€å¯åŒæ—¶ç”Ÿæˆçš„å¹¶è¡ŒåŒ–æ–¹æ³•ï¼ŒBaggingã€Random Forest</li>
</ul>
<h3 id="Boosting"><a href="#Boosting" class="headerlink" title="Boosting"></a>Boosting</h3><p>å°†å¼±å­¦ä¹ å™¨æå‡ä¸ºå¼ºå­¦ä¹ å™¨çš„ç®—æ³•</p>
<p>å…ˆä»åˆå§‹è®­ç»ƒé›†è®­ç»ƒå‡ºä¸€ä¸ªåŸºå­¦ä¹ å™¨ï¼Œå†æ ¹æ®åŸºå­¦ä¹ å™¨çš„è¡¨ç°å¯¹è®­ç»ƒæ ·æœ¬åˆ†å¸ƒè¿›è¡Œè°ƒæ•´ï¼Œä½¿å¾—å…ˆå‰åŸºå­¦ä¹ å™¨åšé”™çš„è®­ç»ƒæ ·æœ¬åœ¨åç»­å¾—åˆ°æ›´å¤šçš„å…³æ³¨ï¼Œç„¶ååŸºäºè°ƒæ•´åçš„æ ·æœ¬åˆ†å¸ƒæ¥è®­ç»ƒä¸‹ä¸€ä¸ªåŸºå­¦ä¹ å™¨</p>
<h4 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h4><p>è¯¯åˆ†ç±»æ ·æœ¬åœ¨ä¸‹ä¸€è½®å­¦ä¹ ä¸­èµ·æ›´å¤§çš„ä½œç”¨</p>
<p>ä¸æ”¹å˜æ‰€ç»™çš„è®­ç»ƒæ•°æ®ï¼Œè€Œä¸æ–­æ”¹å˜å•Šè®­ç»ƒæ•°æ®æƒå€¼çš„éƒ¨åˆ†ï¼Œä½¿å¾—è®­ç»ƒæ•°æ®åœ¨åŸºæœ¬åˆ†ç±»å™¨çš„å­¦ä¹ ä¸­èµ·ä¸åŒçš„ä½œç”¨</p>
<p>å‰ä¸€ä¸ªåŸºæœ¬åˆ†ç±»å™¨åˆ†é”™çš„æ ·æœ¬ä¼šå¾—åˆ°åŠ å¼ºï¼ŒåŠ æƒåçš„å…¨ä½“æ ·æœ¬å†æ¬¡è¢«ç”¨æ¥è®­ç»ƒä¸‹ä¸€ä¸ªåŸºæœ¬åˆ†ç±»å™¨</p>
<p>AdaBoostæ˜¯ä¸€ç§è¿­ä»£ç®—æ³•ï¼Œåœ¨æ¯ä¸€è½®ä¸­åŠ å…¥ä¸€ä¸ªæ–°çš„å¼±åˆ†ç±»å™¨ï¼Œç›´åˆ°è¾¾åˆ°æŸä¸ªé¢„å®šçš„è¶³å¤Ÿå°çš„é”™è¯¯ç‡ã€‚æ¯ä¸€ä¸ªè®­ç»ƒæ ·æœ¬éƒ½è¢«èµ‹äºˆä¸€ä¸ªæƒé‡ï¼Œè¡¨æ˜å®ƒè¢«æŸä¸ªåˆ†ç±»å™¨é€‰å…¥è®­ç»ƒé›†çš„æ¦‚ç‡ã€‚å¦‚æœæŸä¸ªæ ·æœ¬ç‚¹å·²ç»è¢«å‡†ç¡®åœ°åˆ†ç±»ï¼Œé‚£ä¹ˆåœ¨æ„é€ ä¸‹ä¸€ä¸ªè®­ç»ƒé›†ä¸­ï¼Œå®ƒè¢«é€‰ä¸­çš„æ¦‚ç‡å°±è¢«é™ä½ï¼›ç›¸åï¼Œå¦‚æœæŸä¸ªæ ·æœ¬ç‚¹æ²¡æœ‰è¢«å‡†ç¡®åœ°åˆ†ç±»ï¼Œé‚£ä¹ˆå®ƒçš„æƒé‡å°±å¾—åˆ°æé«˜                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </p>
<h3 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h3><p>å¹¶è¡Œå¼é›†æˆå­¦ä¹ </p>
<p><strong>è‡ªä¸»é‡‡æ ·Bootstrap sampling</strong>ï¼šç»™å®šåŒ…å«m ä¸ªæ ·æœ¬çš„æ•°æ®é›†ï¼Œæˆ‘ä»¬å…ˆéšæœºå–å‡ºä¸€ä¸ªæ ·æœ¬æ”¾å…¥é‡‡æ ·é›†ä¸­ï¼Œå†æŠŠè¯¥æ ·æœ¬æ”¾å›åˆå§‹æ•°æ®é›†ï¼Œä½¿å¾—ä¸‹æ¬¡é‡‡æ ·æ—¶è¯¥æ ·æœ¬ä»æœ‰å¯èƒ½è¢«é€‰ä¸­ï¼Œè¿™æ ·ï¼Œç»è¿‡mæ¬¡éšæœºé‡‡æ ·æ“ä½œï¼Œæˆ‘ä»¬å¾—åˆ°å«m ä¸ªæ ·æœ¬çš„é‡‡æ ·é›†ï¼Œåˆå§‹è®­ç»ƒé›†ä¸­æœ‰çš„æ ·æœ¬åœ¨é‡‡æ ·é›†é‡Œå¤šæ¬¡å‡ºç°ï¼Œæœ‰çš„åˆ™ä»æœªå‡ºç°</p>
<p>é‡‡æ ·å‡ºTä¸ªå«mä¸ªè®­ç»ƒæ ·æœ¬çš„é‡‡æ ·é›†ï¼Œç„¶ååŸºäºæ¯ä¸ªé‡‡æ ·é›†è®­ç»ƒå‡ºä¸€ä¸ªåŸºå­¦ä¹ å™¨ï¼Œå†å°†è¿™äº›åŸºå­¦ä¹ å™¨è¿›è¡Œç»“åˆ</p>
<p>æ ‡å‡†Adabooståªé€‚ç”¨äºäºŒåˆ†ç±»ä»»åŠ¡ï¼ŒBaggingèƒ½ä¸ç»ä¿®æ”¹åœ°ç”¨äºå¤šåˆ†ç±»ã€å›å½’ç­‰ä»»åŠ¡</p>
<p>è‡ªä¸»é‡‡æ ·å¸¦æ¥ä¸€ä¸ª<strong>ä¼˜ç‚¹</strong>ï¼šç”±äºæ¯ä¸ªåŸºå­¦ä¹ å™¨åªä½¿ç”¨äº†åˆå§‹è®­ç»ƒé›†ä¸­çº¦63.2%çš„æ ·æœ¬ï¼Œå‰©ä¸‹36.8%çš„æ ·æœ¬å¯ç”¨ä½œéªŒè¯é›†å¯¹æ³›åŒ–æ€§èƒ½è¿›è¡Œâ€œåŒ…å¤–ä¼°è®¡â€ï¼ˆout-of-bag estimateï¼‰</p>
<p>Baggingä¸»è¦å…³æ³¨é™ä½æ–¹å·®ï¼Œå› æ­¤ä»–åœ¨ä¸å‰ªæå†³ç­–æ ‘ã€ç¥ç»ç½‘ç»œç­‰æ˜“å—æ ·æœ¬æ‰°åŠ¨çš„å­¦ä¹ å™¨ä¸Šæ•ˆç”¨æ›´ä¸ºæ˜æ˜¾ã€‚</p>
<h3 id="éšæœºæ£®æ—-Random-Forest"><a href="#éšæœºæ£®æ—-Random-Forest" class="headerlink" title="éšæœºæ£®æ— Random Forest"></a>éšæœºæ£®æ— Random Forest</h3><p>ä»¥å†³ç­–æ ‘ä¸ºåŸºå­¦ä¹ å™¨æ„å»ºBaggingé›†æˆçš„åŸºç¡€ä¸Šï¼Œè¿›ä¸€æ­¥åœ¨å†³ç­–æ ‘çš„è®­ç»ƒè¿‡ç¨‹ä¸­å¼•å…¥éšæœºå±æ€§é€‰æ‹©</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/12/18/Some-points-in-ML/" rel="next" title="Some points in ML">
                <i class="fa fa-chevron-left"></i> Some points in ML
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/03/22/Hierarchical-Attention-Network-for-Document-Classification/" rel="prev" title="Hierarchical Attention Network for Document Classification">
                Hierarchical Attention Network for Document Classification <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/me.JPG"
                alt="Ace_ZAJ" />
            
              <p class="site-author-name" itemprop="name">Ace_ZAJ</p>
              <p class="site-description motion-element" itemprop="description">boom pow</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">127</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          <div class="links-of-author motion-element">
            
          </div>

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Introduction"><span class="nav-number">1.</span> <span class="nav-text">Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Supervised-Learning"><span class="nav-number">1.0.1.</span> <span class="nav-text">Supervised Learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Unsupervised-Learning"><span class="nav-number">1.0.2.</span> <span class="nav-text">Unsupervised Learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Reinforcement-Learning"><span class="nav-number">1.0.3.</span> <span class="nav-text">Reinforcement Learning</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-steps"><span class="nav-number">2.</span> <span class="nav-text">Basic steps</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#generalization-error"><span class="nav-number">2.0.1.</span> <span class="nav-text">generalization error</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Test-sets"><span class="nav-number">2.0.2.</span> <span class="nav-text">Test sets</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Overfitting"><span class="nav-number">2.0.3.</span> <span class="nav-text">Overfitting</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Feature-selection"><span class="nav-number">2.0.4.</span> <span class="nav-text">Feature selection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Model-selection"><span class="nav-number">2.0.5.</span> <span class="nav-text">Model selection</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Regularization"><span class="nav-number">2.0.6.</span> <span class="nav-text">Regularization</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-Polynomial-Curve-Regression-â€“-Bishop-page10"><span class="nav-number">3.</span> <span class="nav-text">1. Polynomial Curve Regression â€“ Bishop page10</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Regularization-1"><span class="nav-number">3.1.</span> <span class="nav-text">Regularization</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-Probability"><span class="nav-number">4.</span> <span class="nav-text">2. Probability</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Probability-densities"><span class="nav-number">4.1.</span> <span class="nav-text">Probability densities</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Expectation"><span class="nav-number">4.2.</span> <span class="nav-text">Expectation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Variance"><span class="nav-number">4.3.</span> <span class="nav-text">Variance</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-Information-Theory"><span class="nav-number">5.</span> <span class="nav-text">3. Information Theory</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-Likelihood-Function"><span class="nav-number">6.</span> <span class="nav-text">4.Likelihood Function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-Linear-Basic-Function-Models"><span class="nav-number">7.</span> <span class="nav-text">5. Linear Basic Function Models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Regularized-least-squares"><span class="nav-number">7.1.</span> <span class="nav-text">Regularized least squares</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#The-Bias-Variance-Decomposition"><span class="nav-number">7.2.</span> <span class="nav-text">The Bias-Variance Decomposition</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bayesian-Linear-Regression"><span class="nav-number">7.3.</span> <span class="nav-text">Bayesian Linear Regression</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6-SVM-â€“-Support-Vector-Machine"><span class="nav-number">8.</span> <span class="nav-text">6. SVM â€“ Support Vector Machine</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#æ‹‰æ ¼æœ—æ—¥ä¹˜æ³•å’ŒKKTæ¡ä»¶"><span class="nav-number">8.1.</span> <span class="nav-text">æ‹‰æ ¼æœ—æ—¥ä¹˜æ³•å’ŒKKTæ¡ä»¶</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-Graphical-Models"><span class="nav-number">9.</span> <span class="nav-text">7. Graphical Models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#é©¬å°”å¯å¤«é“¾ï¼ˆMarkov-Chainï¼‰"><span class="nav-number">9.1.</span> <span class="nav-text">é©¬å°”å¯å¤«é“¾ï¼ˆMarkov Chainï¼‰</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#é©¬å°”å¯å¤«éšæœºåœºï¼ˆMarkov-Random-Fieldï¼‰"><span class="nav-number">9.2.</span> <span class="nav-text">é©¬å°”å¯å¤«éšæœºåœºï¼ˆMarkov Random Fieldï¼‰</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#æ¡ä»¶éšæœºåœºï¼ˆConditional-Random-Field-CRFï¼‰"><span class="nav-number">9.3.</span> <span class="nav-text">æ¡ä»¶éšæœºåœºï¼ˆConditional Random Field CRFï¼‰</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-EMç®—æ³•"><span class="nav-number">10.</span> <span class="nav-text">8. EMç®—æ³•</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9-é›†æˆå­¦ä¹ "><span class="nav-number">11.</span> <span class="nav-text">9. é›†æˆå­¦ä¹ </span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Boosting"><span class="nav-number">11.1.</span> <span class="nav-text">Boosting</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#AdaBoost"><span class="nav-number">11.1.1.</span> <span class="nav-text">AdaBoost</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bagging"><span class="nav-number">11.2.</span> <span class="nav-text">Bagging</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#éšæœºæ£®æ—-Random-Forest"><span class="nav-number">11.3.</span> <span class="nav-text">éšæœºæ£®æ— Random Forest</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ace_ZAJ</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.3</div>




        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.3"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.3"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.3"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.3"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.3"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.3"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.staticfile.org/MathJax/MathJax-2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
